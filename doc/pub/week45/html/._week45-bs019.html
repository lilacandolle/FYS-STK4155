<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week45.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week45-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 45,  Recurrent Neural Networks">
<title>Week 45,  Recurrent Neural Networks</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week45.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week45-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 45', 2, None, 'plan-for-week-45'),
              ('Material for the lab sessions, additional ways to present '
               'classification results and other practicalities',
               2,
               None,
               'material-for-the-lab-sessions-additional-ways-to-present-classification-results-and-other-practicalities'),
              ('Searching for Optimal Regularization Parameters $\\lambda$',
               2,
               None,
               'searching-for-optimal-regularization-parameters-lambda'),
              ('Grid Search', 2, None, 'grid-search'),
              ('Randomized Grid Search', 2, None, 'randomized-grid-search'),
              ('Wisconsin Cancer Data', 2, None, 'wisconsin-cancer-data'),
              ('Using the correlation matrix',
               2,
               None,
               'using-the-correlation-matrix'),
              ('Discussing the correlation data',
               2,
               None,
               'discussing-the-correlation-data'),
              ('Other ways of presenting a classification problem',
               2,
               None,
               'other-ways-of-presenting-a-classification-problem'),
              ('Combinations of classification results',
               2,
               None,
               'combinations-of-classification-results'),
              ('Positive and negative prediction values',
               2,
               None,
               'positive-and-negative-prediction-values'),
              ('Other quantities', 2, None, 'other-quantities'),
              ('$F_1$ score', 2, None, 'f-1-score'),
              ('ROC curve', 2, None, 'roc-curve'),
              ('Cumulative gain curve', 2, None, 'cumulative-gain-curve'),
              ('Other measures in classification studies: Cancer Data  again',
               2,
               None,
               'other-measures-in-classification-studies-cancer-data-again'),
              ('Material for Lecture Thursday November 9',
               2,
               None,
               'material-for-lecture-thursday-november-9'),
              ('Recurrent neural networks (RNNs): Overarching view',
               2,
               None,
               'recurrent-neural-networks-rnns-overarching-view'),
              ('A simple example', 2, None, 'a-simple-example'),
              ('RNNs', 3, None, 'rnns'),
              ('Basic layout', 2, None, 'basic-layout'),
              ('We need to specify the initial activity state of all the '
               'hidden and output units',
               3,
               None,
               'we-need-to-specify-the-initial-activity-state-of-all-the-hidden-and-output-units'),
              ('We can specify inputs in several ways',
               3,
               None,
               'we-can-specify-inputs-in-several-ways'),
              ('We can specify targets in several ways',
               3,
               None,
               'we-can-specify-targets-in-several-ways'),
              ('Backpropagation through time',
               3,
               None,
               'backpropagation-through-time'),
              ('The backward pass is linear',
               3,
               None,
               'the-backward-pass-is-linear'),
              ('The problem of exploding or vanishing gradients',
               2,
               None,
               'the-problem-of-exploding-or-vanishing-gradients'),
              ('Four effective ways to learn an RNN',
               2,
               None,
               'four-effective-ways-to-learn-an-rnn'),
              ('Long Short Term Memory (LSTM)',
               3,
               None,
               'long-short-term-memory-lstm'),
              ('Implementing a memory cell in a neural network',
               3,
               None,
               'implementing-a-memory-cell-in-a-neural-network'),
              ('An extrapolation example', 2, None, 'an-extrapolation-example'),
              ('Formatting the Data', 2, None, 'formatting-the-data'),
              ('Predicting New Points With A Trained Recurrent Neural Network',
               2,
               None,
               'predicting-new-points-with-a-trained-recurrent-neural-network'),
              ('Other Things to Try', 2, None, 'other-things-to-try'),
              ('Other Types of Recurrent Neural Networks',
               2,
               None,
               'other-types-of-recurrent-neural-networks')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week45-bs.html">Week 45,  Recurrent Neural Networks</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week45-bs001.html#plan-for-week-45" style="font-size: 80%;"><b>Plan for week 45</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs002.html#material-for-the-lab-sessions-additional-ways-to-present-classification-results-and-other-practicalities" style="font-size: 80%;"><b>Material for the lab sessions, additional ways to present classification results and other practicalities</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs003.html#searching-for-optimal-regularization-parameters-lambda" style="font-size: 80%;"><b>Searching for Optimal Regularization Parameters \( \lambda \)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs004.html#grid-search" style="font-size: 80%;"><b>Grid Search</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs005.html#randomized-grid-search" style="font-size: 80%;"><b>Randomized Grid Search</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs006.html#wisconsin-cancer-data" style="font-size: 80%;"><b>Wisconsin Cancer Data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs007.html#using-the-correlation-matrix" style="font-size: 80%;"><b>Using the correlation matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs008.html#discussing-the-correlation-data" style="font-size: 80%;"><b>Discussing the correlation data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs009.html#other-ways-of-presenting-a-classification-problem" style="font-size: 80%;"><b>Other ways of presenting a classification problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs010.html#combinations-of-classification-results" style="font-size: 80%;"><b>Combinations of classification results</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs011.html#positive-and-negative-prediction-values" style="font-size: 80%;"><b>Positive and negative prediction values</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs012.html#other-quantities" style="font-size: 80%;"><b>Other quantities</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs013.html#f-1-score" style="font-size: 80%;"><b>\( F_1 \) score</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs014.html#roc-curve" style="font-size: 80%;"><b>ROC curve</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs015.html#cumulative-gain-curve" style="font-size: 80%;"><b>Cumulative gain curve</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs016.html#other-measures-in-classification-studies-cancer-data-again" style="font-size: 80%;"><b>Other measures in classification studies: Cancer Data  again</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs017.html#material-for-lecture-thursday-november-9" style="font-size: 80%;"><b>Material for Lecture Thursday November 9</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs018.html#recurrent-neural-networks-rnns-overarching-view" style="font-size: 80%;"><b>Recurrent neural networks (RNNs): Overarching view</b></a></li>
     <!-- navigation toc: --> <li><a href="#a-simple-example" style="font-size: 80%;"><b>A simple example</b></a></li>
     <!-- navigation toc: --> <li><a href="#rnns" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;RNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#basic-layout" style="font-size: 80%;"><b>Basic layout</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#we-need-to-specify-the-initial-activity-state-of-all-the-hidden-and-output-units" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;We need to specify the initial activity state of all the hidden and output units</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#we-can-specify-inputs-in-several-ways" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;We can specify inputs in several ways</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#we-can-specify-targets-in-several-ways" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;We can specify targets in several ways</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#backpropagation-through-time" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Backpropagation through time</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#the-backward-pass-is-linear" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The backward pass is linear</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs021.html#the-problem-of-exploding-or-vanishing-gradients" style="font-size: 80%;"><b>The problem of exploding or vanishing gradients</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs022.html#four-effective-ways-to-learn-an-rnn" style="font-size: 80%;"><b>Four effective ways to learn an RNN</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs022.html#long-short-term-memory-lstm" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Long Short Term Memory (LSTM)</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs022.html#implementing-a-memory-cell-in-a-neural-network" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Implementing a memory cell in a neural network</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs023.html#an-extrapolation-example" style="font-size: 80%;"><b>An extrapolation example</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs024.html#formatting-the-data" style="font-size: 80%;"><b>Formatting the Data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs025.html#predicting-new-points-with-a-trained-recurrent-neural-network" style="font-size: 80%;"><b>Predicting New Points With A Trained Recurrent Neural Network</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs026.html#other-things-to-try" style="font-size: 80%;"><b>Other Things to Try</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs027.html#other-types-of-recurrent-neural-networks" style="font-size: 80%;"><b>Other Types of Recurrent Neural Networks</b></a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0019"></a>
<!-- !split -->
<h2 id="a-simple-example" class="anchor">A simple example </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #408080; font-style: italic"># Start importing packages</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">pandas</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">pd</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">tensorflow</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">tf</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras</span> <span style="color: #008000; font-weight: bold">import</span> datasets, layers, models
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.layers</span> <span style="color: #008000; font-weight: bold">import</span> Input
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.models</span> <span style="color: #008000; font-weight: bold">import</span> Model, Sequential 
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.layers</span> <span style="color: #008000; font-weight: bold">import</span> Dense, SimpleRNN, LSTM, GRU
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras</span> <span style="color: #008000; font-weight: bold">import</span> optimizers     
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras</span> <span style="color: #008000; font-weight: bold">import</span> regularizers           
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.utils</span> <span style="color: #008000; font-weight: bold">import</span> to_categorical 



<span style="color: #408080; font-style: italic"># convert into dataset matrix</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">convertToMatrix</span>(data, step):
 X, Y <span style="color: #666666">=</span>[], []
 <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #008000">len</span>(data)<span style="color: #666666">-</span>step):
  d<span style="color: #666666">=</span>i<span style="color: #666666">+</span>step  
  X<span style="color: #666666">.</span>append(data[i:d,])
  Y<span style="color: #666666">.</span>append(data[d,])
 <span style="color: #008000; font-weight: bold">return</span> np<span style="color: #666666">.</span>array(X), np<span style="color: #666666">.</span>array(Y)

step <span style="color: #666666">=</span> <span style="color: #666666">4</span>
N <span style="color: #666666">=</span> <span style="color: #666666">1000</span>    
Tp <span style="color: #666666">=</span> <span style="color: #666666">800</span>    

t<span style="color: #666666">=</span>np<span style="color: #666666">.</span>arange(<span style="color: #666666">0</span>,N)
x<span style="color: #666666">=</span>np<span style="color: #666666">.</span>sin(<span style="color: #666666">0.02*</span>t)<span style="color: #666666">+2*</span>np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>rand(N)
df <span style="color: #666666">=</span> pd<span style="color: #666666">.</span>DataFrame(x)
df<span style="color: #666666">.</span>head()

values<span style="color: #666666">=</span>df<span style="color: #666666">.</span>values
train,test <span style="color: #666666">=</span> values[<span style="color: #666666">0</span>:Tp,:], values[Tp:N,:]

<span style="color: #408080; font-style: italic"># add step elements into train and test</span>
test <span style="color: #666666">=</span> np<span style="color: #666666">.</span>append(test,np<span style="color: #666666">.</span>repeat(test[<span style="color: #666666">-1</span>,],step))
train <span style="color: #666666">=</span> np<span style="color: #666666">.</span>append(train,np<span style="color: #666666">.</span>repeat(train[<span style="color: #666666">-1</span>,],step))
 
trainX,trainY <span style="color: #666666">=</span>convertToMatrix(train,step)
testX,testY <span style="color: #666666">=</span>convertToMatrix(test,step)
trainX <span style="color: #666666">=</span> np<span style="color: #666666">.</span>reshape(trainX, (trainX<span style="color: #666666">.</span>shape[<span style="color: #666666">0</span>], <span style="color: #666666">1</span>, trainX<span style="color: #666666">.</span>shape[<span style="color: #666666">1</span>]))
testX <span style="color: #666666">=</span> np<span style="color: #666666">.</span>reshape(testX, (testX<span style="color: #666666">.</span>shape[<span style="color: #666666">0</span>], <span style="color: #666666">1</span>, testX<span style="color: #666666">.</span>shape[<span style="color: #666666">1</span>]))

model <span style="color: #666666">=</span> Sequential()
model<span style="color: #666666">.</span>add(SimpleRNN(units<span style="color: #666666">=32</span>, input_shape<span style="color: #666666">=</span>(<span style="color: #666666">1</span>,step), activation<span style="color: #666666">=</span><span style="color: #BA2121">&quot;relu&quot;</span>))
model<span style="color: #666666">.</span>add(Dense(<span style="color: #666666">8</span>, activation<span style="color: #666666">=</span><span style="color: #BA2121">&quot;relu&quot;</span>)) 
model<span style="color: #666666">.</span>add(Dense(<span style="color: #666666">1</span>))
model<span style="color: #666666">.</span>compile(loss<span style="color: #666666">=</span><span style="color: #BA2121">&#39;mean_squared_error&#39;</span>, optimizer<span style="color: #666666">=</span><span style="color: #BA2121">&#39;rmsprop&#39;</span>)
model<span style="color: #666666">.</span>summary()

model<span style="color: #666666">.</span>fit(trainX,trainY, epochs<span style="color: #666666">=100</span>, batch_size<span style="color: #666666">=16</span>, verbose<span style="color: #666666">=2</span>)
trainPredict <span style="color: #666666">=</span> model<span style="color: #666666">.</span>predict(trainX)
testPredict<span style="color: #666666">=</span> model<span style="color: #666666">.</span>predict(testX)
predicted<span style="color: #666666">=</span>np<span style="color: #666666">.</span>concatenate((trainPredict,testPredict),axis<span style="color: #666666">=0</span>)

trainScore <span style="color: #666666">=</span> model<span style="color: #666666">.</span>evaluate(trainX, trainY, verbose<span style="color: #666666">=0</span>)
<span style="color: #008000">print</span>(trainScore)
plt<span style="color: #666666">.</span>plot(df)
plt<span style="color: #666666">.</span>plot(predicted)
plt<span style="color: #666666">.</span>show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
<h3 id="rnns" class="anchor">RNNs </h3>

<p>RNNs are very powerful, because they
combine two properties:
</p>
<ol>
<li> Distributed hidden state that allows them to store a lot of information about the past efficiently.</li>
<li> Non-linear dynamics that allows them to update their hidden state in complicated ways.</li>
</ol>
<p>With enough neurons and time, RNNs
can compute anything that can be
computed by your computer!
</p>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week45-bs018.html">&laquo;</a></li>
  <li><a href="._week45-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week45-bs011.html">12</a></li>
  <li><a href="._week45-bs012.html">13</a></li>
  <li><a href="._week45-bs013.html">14</a></li>
  <li><a href="._week45-bs014.html">15</a></li>
  <li><a href="._week45-bs015.html">16</a></li>
  <li><a href="._week45-bs016.html">17</a></li>
  <li><a href="._week45-bs017.html">18</a></li>
  <li><a href="._week45-bs018.html">19</a></li>
  <li class="active"><a href="._week45-bs019.html">20</a></li>
  <li><a href="._week45-bs020.html">21</a></li>
  <li><a href="._week45-bs021.html">22</a></li>
  <li><a href="._week45-bs022.html">23</a></li>
  <li><a href="._week45-bs023.html">24</a></li>
  <li><a href="._week45-bs024.html">25</a></li>
  <li><a href="._week45-bs025.html">26</a></li>
  <li><a href="._week45-bs026.html">27</a></li>
  <li><a href="._week45-bs027.html">28</a></li>
  <li><a href="._week45-bs020.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

