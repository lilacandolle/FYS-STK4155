<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week45.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week45-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 45,  Recurrent Neural Networks">
<title>Week 45,  Recurrent Neural Networks</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week45.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week45-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 45', 2, None, 'plan-for-week-45'),
              ('Material for the lab sessions, additional ways to present '
               'classification results and other practicalities',
               2,
               None,
               'material-for-the-lab-sessions-additional-ways-to-present-classification-results-and-other-practicalities'),
              ('Searching for Optimal Regularization Parameters $\\lambda$',
               2,
               None,
               'searching-for-optimal-regularization-parameters-lambda'),
              ('Grid Search', 2, None, 'grid-search'),
              ('Randomized Grid Search', 2, None, 'randomized-grid-search'),
              ('Wisconsin Cancer Data', 2, None, 'wisconsin-cancer-data'),
              ('Using the correlation matrix',
               2,
               None,
               'using-the-correlation-matrix'),
              ('Discussing the correlation data',
               2,
               None,
               'discussing-the-correlation-data'),
              ('Other ways of presenting a classification problem',
               2,
               None,
               'other-ways-of-presenting-a-classification-problem'),
              ('Combinations of classification results',
               2,
               None,
               'combinations-of-classification-results'),
              ('Positive and negative prediction values',
               2,
               None,
               'positive-and-negative-prediction-values'),
              ('Other quantities', 2, None, 'other-quantities'),
              ('$F_1$ score', 2, None, 'f-1-score'),
              ('ROC curve', 2, None, 'roc-curve'),
              ('Cumulative gain curve', 2, None, 'cumulative-gain-curve'),
              ('Other measures in classification studies: Cancer Data  again',
               2,
               None,
               'other-measures-in-classification-studies-cancer-data-again'),
              ('Material for Lecture Thursday November 9',
               2,
               None,
               'material-for-lecture-thursday-november-9'),
              ('Recurrent neural networks (RNNs): Overarching view',
               2,
               None,
               'recurrent-neural-networks-rnns-overarching-view'),
              ('A simple example', 2, None, 'a-simple-example'),
              ('RNNs', 3, None, 'rnns'),
              ('Basic layout', 2, None, 'basic-layout'),
              ('We need to specify the initial activity state of all the '
               'hidden and output units',
               3,
               None,
               'we-need-to-specify-the-initial-activity-state-of-all-the-hidden-and-output-units'),
              ('We can specify inputs in several ways',
               3,
               None,
               'we-can-specify-inputs-in-several-ways'),
              ('We can specify targets in several ways',
               3,
               None,
               'we-can-specify-targets-in-several-ways'),
              ('Backpropagation through time',
               3,
               None,
               'backpropagation-through-time'),
              ('The backward pass is linear',
               3,
               None,
               'the-backward-pass-is-linear'),
              ('The problem of exploding or vanishing gradients',
               2,
               None,
               'the-problem-of-exploding-or-vanishing-gradients'),
              ('Four effective ways to learn an RNN',
               2,
               None,
               'four-effective-ways-to-learn-an-rnn'),
              ('Long Short Term Memory (LSTM)',
               3,
               None,
               'long-short-term-memory-lstm'),
              ('Implementing a memory cell in a neural network',
               3,
               None,
               'implementing-a-memory-cell-in-a-neural-network'),
              ('An extrapolation example', 2, None, 'an-extrapolation-example'),
              ('Formatting the Data', 2, None, 'formatting-the-data'),
              ('Predicting New Points With A Trained Recurrent Neural Network',
               2,
               None,
               'predicting-new-points-with-a-trained-recurrent-neural-network'),
              ('Other Things to Try', 2, None, 'other-things-to-try'),
              ('Other Types of Recurrent Neural Networks',
               2,
               None,
               'other-types-of-recurrent-neural-networks')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week45-bs.html">Week 45,  Recurrent Neural Networks</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week45-bs001.html#plan-for-week-45" style="font-size: 80%;"><b>Plan for week 45</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs002.html#material-for-the-lab-sessions-additional-ways-to-present-classification-results-and-other-practicalities" style="font-size: 80%;"><b>Material for the lab sessions, additional ways to present classification results and other practicalities</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs003.html#searching-for-optimal-regularization-parameters-lambda" style="font-size: 80%;"><b>Searching for Optimal Regularization Parameters \( \lambda \)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs004.html#grid-search" style="font-size: 80%;"><b>Grid Search</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs005.html#randomized-grid-search" style="font-size: 80%;"><b>Randomized Grid Search</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs006.html#wisconsin-cancer-data" style="font-size: 80%;"><b>Wisconsin Cancer Data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs007.html#using-the-correlation-matrix" style="font-size: 80%;"><b>Using the correlation matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs008.html#discussing-the-correlation-data" style="font-size: 80%;"><b>Discussing the correlation data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs009.html#other-ways-of-presenting-a-classification-problem" style="font-size: 80%;"><b>Other ways of presenting a classification problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs010.html#combinations-of-classification-results" style="font-size: 80%;"><b>Combinations of classification results</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs011.html#positive-and-negative-prediction-values" style="font-size: 80%;"><b>Positive and negative prediction values</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs012.html#other-quantities" style="font-size: 80%;"><b>Other quantities</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs013.html#f-1-score" style="font-size: 80%;"><b>\( F_1 \) score</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs014.html#roc-curve" style="font-size: 80%;"><b>ROC curve</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs015.html#cumulative-gain-curve" style="font-size: 80%;"><b>Cumulative gain curve</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs016.html#other-measures-in-classification-studies-cancer-data-again" style="font-size: 80%;"><b>Other measures in classification studies: Cancer Data  again</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs017.html#material-for-lecture-thursday-november-9" style="font-size: 80%;"><b>Material for Lecture Thursday November 9</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs018.html#recurrent-neural-networks-rnns-overarching-view" style="font-size: 80%;"><b>Recurrent neural networks (RNNs): Overarching view</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs019.html#a-simple-example" style="font-size: 80%;"><b>A simple example</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs019.html#rnns" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;RNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#basic-layout" style="font-size: 80%;"><b>Basic layout</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#we-need-to-specify-the-initial-activity-state-of-all-the-hidden-and-output-units" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;We need to specify the initial activity state of all the hidden and output units</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#we-can-specify-inputs-in-several-ways" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;We can specify inputs in several ways</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#we-can-specify-targets-in-several-ways" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;We can specify targets in several ways</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#backpropagation-through-time" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Backpropagation through time</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#the-backward-pass-is-linear" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The backward pass is linear</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs021.html#the-problem-of-exploding-or-vanishing-gradients" style="font-size: 80%;"><b>The problem of exploding or vanishing gradients</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs022.html#four-effective-ways-to-learn-an-rnn" style="font-size: 80%;"><b>Four effective ways to learn an RNN</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs022.html#long-short-term-memory-lstm" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Long Short Term Memory (LSTM)</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs022.html#implementing-a-memory-cell-in-a-neural-network" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Implementing a memory cell in a neural network</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs023.html#an-extrapolation-example" style="font-size: 80%;"><b>An extrapolation example</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs024.html#formatting-the-data" style="font-size: 80%;"><b>Formatting the Data</b></a></li>
     <!-- navigation toc: --> <li><a href="#predicting-new-points-with-a-trained-recurrent-neural-network" style="font-size: 80%;"><b>Predicting New Points With A Trained Recurrent Neural Network</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs026.html#other-things-to-try" style="font-size: 80%;"><b>Other Things to Try</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs027.html#other-types-of-recurrent-neural-networks" style="font-size: 80%;"><b>Other Types of Recurrent Neural Networks</b></a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0025"></a>
<!-- !split -->
<h2 id="predicting-new-points-with-a-trained-recurrent-neural-network" class="anchor">Predicting New Points With A Trained Recurrent Neural Network </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">test_rnn</span> (x1, y_test, plot_min, plot_max):
    <span style="color: #BA2121; font-style: italic">&quot;&quot;&quot;</span>
<span style="color: #BA2121; font-style: italic">        Inputs:</span>
<span style="color: #BA2121; font-style: italic">            x1 (a list or numpy array): The complete x component of the data set</span>
<span style="color: #BA2121; font-style: italic">            y_test (a list or numpy array): The complete y component of the data set</span>
<span style="color: #BA2121; font-style: italic">            plot_min (an int or float): the smallest x value used in the training data</span>
<span style="color: #BA2121; font-style: italic">            plot_max (an int or float): the largest x valye used in the training data</span>
<span style="color: #BA2121; font-style: italic">        Returns:</span>
<span style="color: #BA2121; font-style: italic">            None.</span>
<span style="color: #BA2121; font-style: italic">        Uses a trained recurrent neural network model to predict future points in the </span>
<span style="color: #BA2121; font-style: italic">        series.  Computes the MSE of the predicted data set from the true data set, saves</span>
<span style="color: #BA2121; font-style: italic">        the predicted data set to a csv file, and plots the predicted and true data sets w</span>
<span style="color: #BA2121; font-style: italic">        while also displaying the data range used for training.</span>
<span style="color: #BA2121; font-style: italic">    &quot;&quot;&quot;</span>
    <span style="color: #408080; font-style: italic"># Add the training data as the first dim points in the predicted data array as these</span>
    <span style="color: #408080; font-style: italic"># are known values.</span>
    y_pred <span style="color: #666666">=</span> y_test[:dim]<span style="color: #666666">.</span>tolist()
    <span style="color: #408080; font-style: italic"># Generate the first input to the trained recurrent neural network using the last two </span>
    <span style="color: #408080; font-style: italic"># points of the training data.  Based on how the network was trained this means that it</span>
    <span style="color: #408080; font-style: italic"># will predict the first point in the data set after the training data.  All of the </span>
    <span style="color: #408080; font-style: italic"># brackets are necessary for Tensorflow.</span>
    next_input <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array([[[y_test[dim<span style="color: #666666">-2</span>]], [y_test[dim<span style="color: #666666">-1</span>]]]])
    <span style="color: #408080; font-style: italic"># Save the very last point in the training data set.  This will be used later.</span>
    last <span style="color: #666666">=</span> [y_test[dim<span style="color: #666666">-1</span>]]

    <span style="color: #408080; font-style: italic"># Iterate until the complete data set is created.</span>
    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span> (dim, <span style="color: #008000">len</span>(y_test)):
        <span style="color: #408080; font-style: italic"># Predict the next point in the data set using the previous two points.</span>
        <span style="color: #008000">next</span> <span style="color: #666666">=</span> model<span style="color: #666666">.</span>predict(next_input)
        <span style="color: #408080; font-style: italic"># Append just the number of the predicted data set</span>
        y_pred<span style="color: #666666">.</span>append(<span style="color: #008000">next</span>[<span style="color: #666666">0</span>][<span style="color: #666666">0</span>])
        <span style="color: #408080; font-style: italic"># Create the input that will be used to predict the next data point in the data set.</span>
        next_input <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array([[last, <span style="color: #008000">next</span>[<span style="color: #666666">0</span>]]], dtype<span style="color: #666666">=</span>np<span style="color: #666666">.</span>float64)
        last <span style="color: #666666">=</span> <span style="color: #008000">next</span>

    <span style="color: #408080; font-style: italic"># Print the mean squared error between the known data set and the predicted data set.</span>
    <span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;MSE: &#39;</span>, np<span style="color: #666666">.</span>square(np<span style="color: #666666">.</span>subtract(y_test, y_pred))<span style="color: #666666">.</span>mean())
    <span style="color: #408080; font-style: italic"># Save the predicted data set as a csv file for later use</span>
    name <span style="color: #666666">=</span> datatype <span style="color: #666666">+</span> <span style="color: #BA2121">&#39;Predicted&#39;</span><span style="color: #666666">+</span><span style="color: #008000">str</span>(dim)<span style="color: #666666">+</span><span style="color: #BA2121">&#39;.csv&#39;</span>
    np<span style="color: #666666">.</span>savetxt(name, y_pred, delimiter<span style="color: #666666">=</span><span style="color: #BA2121">&#39;,&#39;</span>)
    <span style="color: #408080; font-style: italic"># Plot the known data set and the predicted data set.  The red box represents the region that was used</span>
    <span style="color: #408080; font-style: italic"># for the training data.</span>
    fig, ax <span style="color: #666666">=</span> plt<span style="color: #666666">.</span>subplots()
    ax<span style="color: #666666">.</span>plot(x1, y_test, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;true&quot;</span>, linewidth<span style="color: #666666">=3</span>)
    ax<span style="color: #666666">.</span>plot(x1, y_pred, <span style="color: #BA2121">&#39;g-.&#39;</span>,label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;predicted&quot;</span>, linewidth<span style="color: #666666">=4</span>)
    ax<span style="color: #666666">.</span>legend()
    <span style="color: #408080; font-style: italic"># Created a red region to represent the points used in the training data.</span>
    ax<span style="color: #666666">.</span>axvspan(plot_min, plot_max, alpha<span style="color: #666666">=0.25</span>, color<span style="color: #666666">=</span><span style="color: #BA2121">&#39;red&#39;</span>)
    plt<span style="color: #666666">.</span>show()

<span style="color: #408080; font-style: italic"># Check to make sure the data set is complete</span>
<span style="color: #008000; font-weight: bold">assert</span> <span style="color: #008000">len</span>(X_tot) <span style="color: #666666">==</span> <span style="color: #008000">len</span>(y_tot)

<span style="color: #408080; font-style: italic"># This is the number of points that will be used in as the training data</span>
dim<span style="color: #666666">=12</span>

<span style="color: #408080; font-style: italic"># Separate the training data from the whole data set</span>
X_train <span style="color: #666666">=</span> X_tot[:dim]
y_train <span style="color: #666666">=</span> y_tot[:dim]


<span style="color: #408080; font-style: italic"># Generate the training data for the RNN, using a sequence of 2</span>
rnn_input, rnn_training <span style="color: #666666">=</span> format_data(y_train, <span style="color: #666666">2</span>)


<span style="color: #408080; font-style: italic"># Create a recurrent neural network in Keras and produce a summary of the </span>
<span style="color: #408080; font-style: italic"># machine learning model</span>
model <span style="color: #666666">=</span> rnn(length_of_sequences <span style="color: #666666">=</span> rnn_input<span style="color: #666666">.</span>shape[<span style="color: #666666">1</span>])
model<span style="color: #666666">.</span>summary()

<span style="color: #408080; font-style: italic"># Start the timer.  Want to time training+testing</span>
start <span style="color: #666666">=</span> timer()
<span style="color: #408080; font-style: italic"># Fit the model using the training data genenerated above using 150 training iterations and a 5%</span>
<span style="color: #408080; font-style: italic"># validation split.  Setting verbose to True prints information about each training iteration.</span>
hist <span style="color: #666666">=</span> model<span style="color: #666666">.</span>fit(rnn_input, rnn_training, batch_size<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">None</span>, epochs<span style="color: #666666">=150</span>, 
                 verbose<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>,validation_split<span style="color: #666666">=0.05</span>)

<span style="color: #008000; font-weight: bold">for</span> label <span style="color: #AA22FF; font-weight: bold">in</span> [<span style="color: #BA2121">&quot;loss&quot;</span>,<span style="color: #BA2121">&quot;val_loss&quot;</span>]:
    plt<span style="color: #666666">.</span>plot(hist<span style="color: #666666">.</span>history[label],label<span style="color: #666666">=</span>label)

plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&quot;loss&quot;</span>)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&quot;epoch&quot;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&quot;The final validation loss: </span><span style="color: #BB6688; font-weight: bold">{}</span><span style="color: #BA2121">&quot;</span><span style="color: #666666">.</span>format(hist<span style="color: #666666">.</span>history[<span style="color: #BA2121">&quot;val_loss&quot;</span>][<span style="color: #666666">-1</span>]))
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>show()

<span style="color: #408080; font-style: italic"># Use the trained neural network to predict more points of the data set</span>
test_rnn(X_tot, y_tot, X_tot[<span style="color: #666666">0</span>], X_tot[dim<span style="color: #666666">-1</span>])
<span style="color: #408080; font-style: italic"># Stop the timer and calculate the total time needed.</span>
end <span style="color: #666666">=</span> timer()
<span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;Time: &#39;</span>, end<span style="color: #666666">-</span>start)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week45-bs024.html">&laquo;</a></li>
  <li><a href="._week45-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week45-bs017.html">18</a></li>
  <li><a href="._week45-bs018.html">19</a></li>
  <li><a href="._week45-bs019.html">20</a></li>
  <li><a href="._week45-bs020.html">21</a></li>
  <li><a href="._week45-bs021.html">22</a></li>
  <li><a href="._week45-bs022.html">23</a></li>
  <li><a href="._week45-bs023.html">24</a></li>
  <li><a href="._week45-bs024.html">25</a></li>
  <li class="active"><a href="._week45-bs025.html">26</a></li>
  <li><a href="._week45-bs026.html">27</a></li>
  <li><a href="._week45-bs027.html">28</a></li>
  <li><a href="._week45-bs026.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

