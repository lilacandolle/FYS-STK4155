<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week44.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week44-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 44,  Convolutional Neural Networks (CNN)">
<title>Week 44,  Convolutional Neural Networks (CNN)</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week44.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week44-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 44', 2, None, 'plan-for-week-44'),
              ('Material for Lecture Thursday November 2',
               2,
               None,
               'material-for-lecture-thursday-november-2'),
              ('Convolutional Neural Networks (recognizing images)',
               2,
               None,
               'convolutional-neural-networks-recognizing-images'),
              ('What is the Difference', 2, None, 'what-is-the-difference'),
              ('Neural Networks vs CNNs', 2, None, 'neural-networks-vs-cnns'),
              ('Why CNNS for images, sound files, medical images from CT scans '
               'etc?',
               2,
               None,
               'why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc'),
              ('Regular NNs donâ€™t scale well to full images',
               2,
               None,
               'regular-nns-don-t-scale-well-to-full-images'),
              ('3D volumes of neurons', 2, None, '3d-volumes-of-neurons'),
              ('Layers used to build CNNs',
               2,
               None,
               'layers-used-to-build-cnns'),
              ('Transforming images', 2, None, 'transforming-images'),
              ('CNNs in brief', 2, None, 'cnns-in-brief'),
              ('Key Idea', 2, None, 'key-idea'),
              ('Mathematics of CNNs', 2, None, 'mathematics-of-cnns'),
              ('Convolution Examples: Polynomial multiplication',
               2,
               None,
               'convolution-examples-polynomial-multiplication'),
              ('Efficient Polynomial Multiplication',
               2,
               None,
               'efficient-polynomial-multiplication'),
              ('A more efficient way of coding the above Convolution',
               2,
               None,
               'a-more-efficient-way-of-coding-the-above-convolution'),
              ('Convolution Examples: Principle of Superposition and Periodic '
               'Forces (Fourier Transforms)',
               2,
               None,
               'convolution-examples-principle-of-superposition-and-periodic-forces-fourier-transforms'),
              ('Simple Code Example', 2, None, 'simple-code-example'),
              ('Wrapping up Fourier transforms',
               2,
               None,
               'wrapping-up-fourier-transforms'),
              ('Finding the Coefficients', 2, None, 'finding-the-coefficients'),
              ('Final words on Fourier Transforms',
               2,
               None,
               'final-words-on-fourier-transforms'),
              ('Fourier transforms and convolution',
               3,
               None,
               'fourier-transforms-and-convolution'),
              ('Two-dimensional Objects', 2, None, 'two-dimensional-objects'),
              ('More on Dimensionalities', 2, None, 'more-on-dimensionalities'),
              ('Further Dimensionality Remarks',
               2,
               None,
               'further-dimensionality-remarks'),
              ('CNNs in more detail', 2, None, 'cnns-in-more-detail'),
              ('Pooling', 2, None, 'pooling'),
              ('No zero padding, unit strides',
               2,
               None,
               'no-zero-padding-unit-strides'),
              ('Zero padding, unit strides',
               2,
               None,
               'zero-padding-unit-strides'),
              ('Half (same) padding', 2, None, 'half-same-padding'),
              ('Full padding', 2, None, 'full-padding'),
              ('Pooling arithmetic', 2, None, 'pooling-arithmetic'),
              ('CNNs in more detail, building convolutional neural networks in '
               'Tensorflow and Keras',
               2,
               None,
               'cnns-in-more-detail-building-convolutional-neural-networks-in-tensorflow-and-keras'),
              ('Setting it up', 2, None, 'setting-it-up'),
              ('The MNIST dataset again', 2, None, 'the-mnist-dataset-again'),
              ('Strong correlations', 2, None, 'strong-correlations'),
              ('Layers of a CNN', 2, None, 'layers-of-a-cnn'),
              ('Systematic reduction', 2, None, 'systematic-reduction'),
              ('Prerequisites: Collect and pre-process data',
               2,
               None,
               'prerequisites-collect-and-pre-process-data'),
              ('Importing Keras and Tensorflow',
               2,
               None,
               'importing-keras-and-tensorflow'),
              ('Running with Keras', 2, None, 'running-with-keras'),
              ('Final part', 2, None, 'final-part'),
              ('Final visualization', 2, None, 'final-visualization'),
              ('The CIFAR01 data set', 2, None, 'the-cifar01-data-set'),
              ('Verifying the data set', 2, None, 'verifying-the-data-set'),
              ('Set up  the model', 2, None, 'set-up-the-model'),
              ('Add Dense layers on top', 2, None, 'add-dense-layers-on-top'),
              ('Compile and train the model',
               2,
               None,
               'compile-and-train-the-model'),
              ('Finally, evaluate the model',
               2,
               None,
               'finally-evaluate-the-model'),
              ('Building our own CNN code',
               2,
               None,
               'building-our-own-cnn-code'),
              ('List of contents:', 3, None, 'list-of-contents'),
              ('Schedulers', 3, None, 'schedulers'),
              ('Usage of schedulers', 3, None, 'usage-of-schedulers'),
              ('Cost functions', 3, None, 'cost-functions'),
              ('Usage of cost functions', 3, None, 'usage-of-cost-functions'),
              ('Activation functions', 3, None, 'activation-functions'),
              ('Usage of activation functions',
               3,
               None,
               'usage-of-activation-functions'),
              ('Convolution', 3, None, 'convolution'),
              ('Layers', 3, None, 'layers'),
              ('Convolution2DLayer: convolution in a hidden layer',
               3,
               None,
               'convolution2dlayer-convolution-in-a-hidden-layer'),
              ('Backpropagation in the convolutional layer',
               3,
               None,
               'backpropagation-in-the-convolutional-layer'),
              ('Demonstration', 3, None, 'demonstration'),
              ('Pooling Layer', 3, None, 'pooling-layer'),
              ('Flattening Layer', 3, None, 'flattening-layer'),
              ('Fully Connected Layers', 3, None, 'fully-connected-layers'),
              ('Optimized Convolution2DLayer',
               3,
               None,
               'optimized-convolution2dlayer'),
              ('The Convolutional Neural Network (CNN)',
               3,
               None,
               'the-convolutional-neural-network-cnn'),
              ('Usage of CNN code', 3, None, 'usage-of-cnn-code'),
              ('Additional Remarks', 3, None, 'additional-remarks'),
              ('Remarks on the speed', 3, None, 'remarks-on-the-speed'),
              ('Convolution using separable kernels',
               3,
               None,
               'convolution-using-separable-kernels'),
              ('Convolution in the Fourier domain',
               3,
               None,
               'convolution-in-the-fourier-domain')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week44-bs.html">Week 44,  Convolutional Neural Networks (CNN)</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week44-bs001.html#plan-for-week-44" style="font-size: 80%;"><b>Plan for week 44</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs002.html#material-for-lecture-thursday-november-2" style="font-size: 80%;"><b>Material for Lecture Thursday November 2</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs003.html#convolutional-neural-networks-recognizing-images" style="font-size: 80%;"><b>Convolutional Neural Networks (recognizing images)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs004.html#what-is-the-difference" style="font-size: 80%;"><b>What is the Difference</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs005.html#neural-networks-vs-cnns" style="font-size: 80%;"><b>Neural Networks vs CNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs006.html#why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc" style="font-size: 80%;"><b>Why CNNS for images, sound files, medical images from CT scans etc?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs007.html#regular-nns-don-t-scale-well-to-full-images" style="font-size: 80%;"><b>Regular NNs donâ€™t scale well to full images</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs008.html#3d-volumes-of-neurons" style="font-size: 80%;"><b>3D volumes of neurons</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs009.html#layers-used-to-build-cnns" style="font-size: 80%;"><b>Layers used to build CNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs010.html#transforming-images" style="font-size: 80%;"><b>Transforming images</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs011.html#cnns-in-brief" style="font-size: 80%;"><b>CNNs in brief</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs012.html#key-idea" style="font-size: 80%;"><b>Key Idea</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs013.html#mathematics-of-cnns" style="font-size: 80%;"><b>Mathematics of CNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs014.html#convolution-examples-polynomial-multiplication" style="font-size: 80%;"><b>Convolution Examples: Polynomial multiplication</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs015.html#efficient-polynomial-multiplication" style="font-size: 80%;"><b>Efficient Polynomial Multiplication</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs016.html#a-more-efficient-way-of-coding-the-above-convolution" style="font-size: 80%;"><b>A more efficient way of coding the above Convolution</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs017.html#convolution-examples-principle-of-superposition-and-periodic-forces-fourier-transforms" style="font-size: 80%;"><b>Convolution Examples: Principle of Superposition and Periodic Forces (Fourier Transforms)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs018.html#simple-code-example" style="font-size: 80%;"><b>Simple Code Example</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs019.html#wrapping-up-fourier-transforms" style="font-size: 80%;"><b>Wrapping up Fourier transforms</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs020.html#finding-the-coefficients" style="font-size: 80%;"><b>Finding the Coefficients</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs021.html#final-words-on-fourier-transforms" style="font-size: 80%;"><b>Final words on Fourier Transforms</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs021.html#fourier-transforms-and-convolution" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Fourier transforms and convolution</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs021.html#two-dimensional-objects" style="font-size: 80%;"><b>Two-dimensional Objects</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs022.html#more-on-dimensionalities" style="font-size: 80%;"><b>More on Dimensionalities</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs023.html#further-dimensionality-remarks" style="font-size: 80%;"><b>Further Dimensionality Remarks</b></a></li>
     <!-- navigation toc: --> <li><a href="#cnns-in-more-detail" style="font-size: 80%;"><b>CNNs in more detail</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs025.html#pooling" style="font-size: 80%;"><b>Pooling</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs026.html#no-zero-padding-unit-strides" style="font-size: 80%;"><b>No zero padding, unit strides</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs027.html#zero-padding-unit-strides" style="font-size: 80%;"><b>Zero padding, unit strides</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs028.html#half-same-padding" style="font-size: 80%;"><b>Half (same) padding</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs029.html#full-padding" style="font-size: 80%;"><b>Full padding</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs030.html#pooling-arithmetic" style="font-size: 80%;"><b>Pooling arithmetic</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs031.html#cnns-in-more-detail-building-convolutional-neural-networks-in-tensorflow-and-keras" style="font-size: 80%;"><b>CNNs in more detail, building convolutional neural networks in Tensorflow and Keras</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs032.html#setting-it-up" style="font-size: 80%;"><b>Setting it up</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs033.html#the-mnist-dataset-again" style="font-size: 80%;"><b>The MNIST dataset again</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs034.html#strong-correlations" style="font-size: 80%;"><b>Strong correlations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#layers-of-a-cnn" style="font-size: 80%;"><b>Layers of a CNN</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs036.html#systematic-reduction" style="font-size: 80%;"><b>Systematic reduction</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs037.html#prerequisites-collect-and-pre-process-data" style="font-size: 80%;"><b>Prerequisites: Collect and pre-process data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs038.html#importing-keras-and-tensorflow" style="font-size: 80%;"><b>Importing Keras and Tensorflow</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs039.html#running-with-keras" style="font-size: 80%;"><b>Running with Keras</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs040.html#final-part" style="font-size: 80%;"><b>Final part</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs041.html#final-visualization" style="font-size: 80%;"><b>Final visualization</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs042.html#the-cifar01-data-set" style="font-size: 80%;"><b>The CIFAR01 data set</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs043.html#verifying-the-data-set" style="font-size: 80%;"><b>Verifying the data set</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs044.html#set-up-the-model" style="font-size: 80%;"><b>Set up  the model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs045.html#add-dense-layers-on-top" style="font-size: 80%;"><b>Add Dense layers on top</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs046.html#compile-and-train-the-model" style="font-size: 80%;"><b>Compile and train the model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs047.html#finally-evaluate-the-model" style="font-size: 80%;"><b>Finally, evaluate the model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#building-our-own-cnn-code" style="font-size: 80%;"><b>Building our own CNN code</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#list-of-contents" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;List of contents:</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#schedulers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Schedulers</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#usage-of-schedulers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of schedulers</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#cost-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Cost functions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#usage-of-cost-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of cost functions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#activation-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Activation functions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#usage-of-activation-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of activation functions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#convolution" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#layers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Layers</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#convolution2dlayer-convolution-in-a-hidden-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution2DLayer: convolution in a hidden layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#backpropagation-in-the-convolutional-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Backpropagation in the convolutional layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#demonstration" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Demonstration</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#pooling-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Pooling Layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#flattening-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Flattening Layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#fully-connected-layers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Fully Connected Layers</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#optimized-convolution2dlayer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Optimized Convolution2DLayer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#the-convolutional-neural-network-cnn" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The Convolutional Neural Network (CNN)</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#usage-of-cnn-code" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of CNN code</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#additional-remarks" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Additional Remarks</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#remarks-on-the-speed" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Remarks on the speed</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#convolution-using-separable-kernels" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution using separable kernels</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#convolution-in-the-fourier-domain" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution in the Fourier domain</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0024"></a>
<!-- !split -->
<h2 id="cnns-in-more-detail" class="anchor">CNNs in more detail </h2>

<p>Let assume we have an input matrix \( I \) of dimensionality \( 3\times 3 \)
and a \( 2\times 2 \) filter \( W \) given by the following matrices
</p>

$$
\boldsymbol{I}=\begin{bmatrix}i_{00} & i_{01} & i_{02}  \\
                      i_{10} & i_{11} & i_{12}  \\
	              i_{20} & i_{21} & i_{22} \end{bmatrix},
$$

<p>and </p>
$$
\boldsymbol{W}=\begin{bmatrix}w_{00} & w_{01} \\
	              w_{10} & w_{11}\end{bmatrix}.
$$

<p>We introduce now the hyperparameter \( S \) <b>stride</b>. Stride represents how the filter \( W \) moves the convolution process on the matrix \( I \).
We strongly recommend the repository on <a href="https://github.com/vdumoulin/conv_arithmetic" target="_self">Arithmetic of deep learning by Dumoulin and Visin</a> 
</p>

<p>Here we set the stride equal to \( S=1 \), which means that, starting with the element \( i_{00} \), the filter will act on \( 2\times 2 \) submatrices each time, starting with the upper corner and moving according to the stride value column by column. </p>

<p>Here we perform the operation</p>
$$
S_(i,j)=(I * W)(i,j) = \sum_m\sum_n I(i-m,j-n)W(m,n),
$$

<p>and obtain</p>
$$
\boldsymbol{S}=\begin{bmatrix}i_{00}w_{00}+i_{01}w_{01}+i_{10}w_{10}+i_{11}w_{11} & i_{01}w_{00}+i_{02}w_{01}+i_{11}w_{10}+i_{12}w_{11}  \\
	              i_{10}w_{00}+i_{11}w_{01}+i_{20}w_{10}+i_{21}w_{11} & i_{11}w_{00}+i_{12}w_{01}+i_{21}w_{10}+i_{22}w_{11}\end{bmatrix}.
$$

<p>We can rewrite this operation in terms of a matrix-vector multiplication by defining a new vector where we flatten out the inputs as a vector \( \boldsymbol{I}' \) of length \( 9 \) and
a matrix \( \boldsymbol{W}' \) with dimension \( 4\times 9 \) as
</p>

$$
\boldsymbol{I}'=\begin{bmatrix}i_{00} \\ i_{01} \\ i_{02} \\ i_{10} \\ i_{11} \\ i_{12} \\ i_{20} \\ i_{21} \\ i_{22} \end{bmatrix},
$$

<p>and the new matrix</p>
$$
\boldsymbol{W}'=\begin{bmatrix} w_{00} & w_{01} & 0 & w_{10} & w_{11} & 0 & 0 & 0 & 0 \\
                        0  & w_{00} & w_{01} & 0 & w_{10} & w_{11} & 0 & 0 & 0 \\
			0 & 0 & 0 & w_{00} & w_{01} & 0 & w_{10} & w_{11} & 0  \\
                        0 & 0 & 0 & 0 & w_{00} & w_{01} & 0 & w_{10} & w_{11}\end{bmatrix}.
$$

<p>We see easily that performing the matrix-vector multiplication \( \boldsymbol{W}'\boldsymbol{I}' \) is the same as the above convolution with stride \( S=1 \), that is</p>

$$
S=(\boldsymbol{W}*\boldsymbol{I}),
$$

<p>is now given by \( \boldsymbol{W}'\boldsymbol{I}' \) which is a vector of length \( 4 \) instead of the originally resulting  \( 2\times 2 \) output matrix.</p>

<p>The collection of kernels/filters \( W \) defining a discrete convolution has a shape
corresponding to some permutation of \( (n, m, k_1, \ldots, k_N) \), where
</p>

$$
\begin{equation*}
\begin{split}
    n &\equiv \text{number of output feature maps},\\
    m &\equiv \text{number of input feature maps},\\
    k_j &\equiv \text{kernel size along axis $j$}.
\end{split}
\end{equation*}
$$

<p>The following properties affect the output size \( o_j \) of a convolutional layer
along axis \( j \):
</p>

<ol>
<li> \( i_j \): input size along axis \( j \),</li>
<li> \( k_j \): kernel/filter size along axis \( j \),</li>
<li> stride (distance between two consecutive positions of the kernel/filter) along axis \( j \),</li>
<li> zero padding (number of zeros concatenated at the beginning and at the end of an axis) along axis \( j \).</li>
</ol>
<p>For instance, the above examples shows a  \( 2\times 2 \) kernel/filter \( \boldsymbol{W} \)  applied to a \( 3 \times 3 \) input padded with a \( 0 \times 0 \)
border of zeros using \( 1 \times 1 \) strides.
</p>

<p>Note that strides constitute a form of <b>subsampling</b>. As an alternative to
being interpreted as a measure of how much the kernel/filter is translated, strides
can also be viewed as how much of the output is retained. For instance, moving
the kernel by hops of two is equivalent to moving the kernel by hops of one but
retaining only odd output elements.
</p>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week44-bs023.html">&laquo;</a></li>
  <li><a href="._week44-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week44-bs016.html">17</a></li>
  <li><a href="._week44-bs017.html">18</a></li>
  <li><a href="._week44-bs018.html">19</a></li>
  <li><a href="._week44-bs019.html">20</a></li>
  <li><a href="._week44-bs020.html">21</a></li>
  <li><a href="._week44-bs021.html">22</a></li>
  <li><a href="._week44-bs022.html">23</a></li>
  <li><a href="._week44-bs023.html">24</a></li>
  <li class="active"><a href="._week44-bs024.html">25</a></li>
  <li><a href="._week44-bs025.html">26</a></li>
  <li><a href="._week44-bs026.html">27</a></li>
  <li><a href="._week44-bs027.html">28</a></li>
  <li><a href="._week44-bs028.html">29</a></li>
  <li><a href="._week44-bs029.html">30</a></li>
  <li><a href="._week44-bs030.html">31</a></li>
  <li><a href="._week44-bs031.html">32</a></li>
  <li><a href="._week44-bs032.html">33</a></li>
  <li><a href="._week44-bs033.html">34</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week44-bs048.html">49</a></li>
  <li><a href="._week44-bs025.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

